# üê≥ Docker & Containerization: The Complete Guide for Modern Backend Engineers

> *This blog is a living document. We'll keep adding to it as we explore more of Docker's ecosystem ‚Äî volumes, networks, Docker Compose, registries, and beyond. Bookmark it!*

---

Hey there, backend explorer! üëã

Let me ask you something. Have you ever spent a whole afternoon setting up a project, got it perfectly running on your machine, sent it to a teammate ‚Äî and they came back with *"It doesn't work on my system"*?

Yeah. We've all been there.

That's the exact problem that made the entire software industry stop and say: *"There HAS to be a better way."*

That better way is **Docker**.

---

## The "It Works on My Machine" Problem üíÄ

Let's be honest about what modern backend development actually looks like. You're juggling:

- Node.js (maybe v20 on your machine, v18 on the server)
- PostgreSQL (you installed it via Homebrew; your teammate's on Linux using `apt`)
- Redis, Nginx, environment variables, OS-level dependencies...

And all of these need to be **exactly right** or things break in mysterious, nightmarish ways.

**The traditional solution?** "Hey, here's a 47-step setup guide. Good luck." üòÖ

**The Docker solution?** "Here's one command. Everything is already configured."

```bash
docker run postgres
```

That's it. Postgres is running. No install wizards. No version conflicts. No dependency hell.

This is the power of **containerization** ‚Äî the idea that your application and ALL its dependencies get bundled together into a single, self-sufficient unit that runs the same way everywhere.

---

## The Big Mental Model: OS ‚Üí Machine :: Image ‚Üí Container üß†

Here's the analogy that makes everything click ‚Äî and it comes straight from how operating systems work.

Think about **Windows** running on your laptop. Windows needs a machine (hardware) to actually run. The OS itself is just instructions ‚Äî it doesn't *do* anything sitting on a USB stick. It needs to be loaded onto hardware, given CPU and RAM, and *executed*.

**Now map that to Docker:**

```
Windows OS        ‚Üí  Docker Image
Your Laptop       ‚Üí  Docker Container
```

- A **Docker Image** is like an OS installation disk ‚Äî it's a **blueprint**, a read-only snapshot with everything your application needs to run (the runtime, code, libraries, config).
- A **Docker Container** is what happens when you actually *run* that image ‚Äî it's a **live, running process** with its own isolated environment.

The image is static. The container is alive.

You can take one image and spin up 10 containers from it, just like you could theoretically install the same Windows ISO on 10 different laptops. Each laptop runs independently, with its own files, processes, and data.

---

## Containers: Isolated Universes üåå

This isolation is the other big idea you need to deeply understand.

Just like two laptops running the same Windows OS are completely separate ‚Äî your files don't magically appear on your friend's machine ‚Äî **two Docker containers are completely isolated from each other**.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Docker Host (Your Machine)        ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  Container A     ‚îÇ    ‚îÇ  Container B     ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ postgres   ‚îÇ  ‚îÇ    ‚îÇ  ‚îÇ  ubuntu    ‚îÇ  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ image      ‚îÇ  ‚îÇ    ‚îÇ  ‚îÇ  image     ‚îÇ  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  Port: 5432      ‚îÇ    ‚îÇ  Port: 80        ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  /var/data/...   ‚îÇ    ‚îÇ  /var/data/...   ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Container A runs Postgres. Container B runs Ubuntu. They cannot see each other's files, processes, or memory ‚Äî **unless you explicitly connect them**. They live in their own little universes.

This isolation gives you:

- üîí **Security**: A compromised container can't easily break out to others
- üßπ **Cleanliness**: Kill a container and everything inside it vanishes ‚Äî no leftover files polluting your system
- üîÑ **Reproducibility**: Same environment, same behavior, every single time

---

## Docker vs Virtual Machines: Why Docker Won ü•ä

Before Docker, if you wanted isolation, you used a **Virtual Machine (VM)**. Both solve the "works on my machine" problem, but in very different ways.

### Virtual Machines: The Heavy Approach

A VM runs a **full, separate operating system** on top of your hardware via something called a **hypervisor** (like VirtualBox or VMware).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Your Machine               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ       Hypervisor (VMware)      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  VM 1    ‚îÇ  ‚îÇ  VM 2    ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Full OS  ‚îÇ  ‚îÇ Full OS  ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ~20GB    ‚îÇ  ‚îÇ ~20GB    ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ App      ‚îÇ  ‚îÇ App      ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Docker: The Lightweight Approach

Docker containers **share the host OS kernel**. They don't need their own full OS ‚Äî they just bundle only what's different or unique about their environment.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Your Machine                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ          Host OS (Your Linux/Mac/Win)   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ        Docker Engine               ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇContainer1‚îÇ   ‚îÇContainer2‚îÇ      ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ ~50MB    ‚îÇ   ‚îÇ ~200MB   ‚îÇ      ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ App      ‚îÇ   ‚îÇ App      ‚îÇ      ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

The difference in practice:

| Feature | Virtual Machine | Docker Container |
|---------|----------------|-----------------|
| **Boot Time** | 1‚Äì5 minutes | Milliseconds |
| **Size** | GBs (full OS) | MBs (just the app layer) |
| **Resource Usage** | Heavy (dedicated CPU/RAM) | Light (shared OS kernel) |
| **Isolation** | Complete (separate kernel) | Process-level isolation |
| **Portability** | OK, but heavy | Excellent |
| **Use Case** | Full OS-level isolation needed | App packaging & microservices |

> ** Insight üß†**: Docker containers aren't "mini VMs". They're isolated **processes** running on the same kernel. This is why they're so fast and lightweight ‚Äî but also why a container running a Linux image needs a Linux kernel to host it (Docker Desktop on Mac/Windows runs a tiny Linux VM behind the scenes to handle this).

---

## Installing Docker: Get Up and Running üõ†Ô∏è

### The Easiest Way: Docker Desktop

Head to [docker.com](https://www.docker.com/products/docker-desktop/) and download **Docker Desktop** for your OS (Mac, Windows, or Linux). It gives you:

- The **Docker Engine** (the core runtime)
- The **Docker CLI** (the command-line tool you'll live in)
- A nice GUI if you want to see what's running visually

After installing, verify everything works:

```bash
docker --version
# Docker version 24.0.5, build ced0996

docker run hello-world
# Hello from Docker! This message shows that...
```

If you see that "Hello from Docker!" message, you're good to go. üéâ

### What Just Happened?

When you ran `docker run hello-world`:

1. Docker looked for the `hello-world` **image** on your machine ‚Äî didn't find it
2. It automatically pulled it from **Docker Hub** (the public image registry, like npm for Docker)
3. It created a **container** from that image and ran it
4. The container printed its message and exited

That whole flow ‚Äî pull image ‚Üí create container ‚Üí run it ‚Üí exit ‚Äî happened in seconds.

---

## Docker Images vs Docker Containers: Nailed Down üìå

This distinction trips up almost every newcomer. Let's kill the confusion for good.

### Images: The Blueprint

Think of a Docker **image** as a **recipe** or a **class definition in code**.

```javascript
// This is like a Docker Image ‚Äî a blueprint, not the thing itself
class PostgresDatabase {
  port = 5432;
  data = {};
  // ... all the instructions
}
```

An image:
- Is **immutable** (read-only, never changes once built)
- Is **layered** (built in steps, each step is a layer cached for efficiency)
- Sits on **Docker Hub** or your local image cache
- Does **nothing** on its own ‚Äî it needs to be run

```bash
# List images on your machine
docker images

# REPOSITORY    TAG       IMAGE ID       CREATED        SIZE
# postgres      latest    a1b2c3d4e5f6   2 weeks ago    376MB
# ubuntu        22.04     7f3b2c8d9e0f   3 weeks ago    69.2MB
# node          18-alpine  4a5b6c7d8e9f  4 weeks ago    113MB
```

### Containers: The Running Instance

A **container** is what you get when you actually *run* an image ‚Äî like creating an **object from a class**.

```javascript
// This is like a Docker Container ‚Äî the actual running instance
const myPostgresDB = new PostgresDatabase(); // Now it's alive!
```

A container:
- Has its own **filesystem, network, and process space**
- Has **state** ‚Äî it can be running, stopped, or paused
- Can be **started and stopped** without losing data (by default)
- Is **ephemeral** ‚Äî remove it and it's gone (unless you use volumes)

```bash
# List running containers
docker ps

# CONTAINER ID   IMAGE      COMMAND               STATUS         PORTS
# a1b2c3d4e5f6   postgres   "docker-entrypoint‚Ä¶"  Up 5 minutes   0.0.0.0:5432->5432/tcp
```

### The Relationship in One Line

> **Image** : **Container** = **Class** : **Object** = **Program** : **Process** = **Recipe** : **Meal**

---

## The Docker CLI: Your Daily Driver üñ•Ô∏è

The Docker CLI is how you talk to Docker. Once you internalize these commands, Docker becomes second nature.

### Working with Images

```bash
# Pull an image from Docker Hub (like npm install but for services)
docker pull postgres
docker pull ubuntu:22.04        # Specific version using a tag
docker pull node:18-alpine      # Alpine = ultra-minimal Linux (~5MB vs ~1GB)

# List all images on your machine
docker images

# Remove an image
docker rmi postgres
docker rmi a1b2c3d4e5f6         # Using image ID

# Search Docker Hub from the terminal
docker search redis
```

### Running Containers

```bash
# Basic run ‚Äî run and attach to it
docker run ubuntu

# Run in detached mode (background) ‚Äî the -d flag
docker run -d postgres

# Run with a name (so you don't have to use ugly IDs)
docker run -d --name my-postgres postgres

# Run with port mapping ‚Äî host:container
# "Make port 5432 inside the container accessible on port 5432 of MY machine"
docker run -d -p 5432:5432 --name my-postgres postgres

# Run with environment variables (Postgres needs these)
docker run -d \
  --name my-postgres \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -e POSTGRES_USER=admin \
  -e POSTGRES_DB=myapp \
  -p 5432:5432 \
  postgres

# Run interactively (get a shell inside the container)
docker run -it ubuntu bash
#                ‚Üë‚Üë‚Üë
#                Interactive + TTY (gives you a terminal)
```

> **Another Insight üß†**: The `-p HOST:CONTAINER` flag is crucial for connecting to services. The container might be listening on port 5432, but without `-p 5432:5432`, nothing outside the container can reach it. Think of it like port forwarding on a router.

### Managing Running Containers

```bash
# List running containers
docker ps

# List ALL containers (including stopped ones)
docker ps -a

# Stop a running container (graceful, sends SIGTERM)
docker stop my-postgres

# Kill a container (immediate, sends SIGKILL ‚Äî use when stop hangs)
docker kill my-postgres

# Start a stopped container (keeps all its data!)
docker start my-postgres

# Restart a container
docker restart my-postgres

# Remove a container (must be stopped first)
docker rm my-postgres

# Remove a running container forcefully
docker rm -f my-postgres

# Stop and remove in one go (common pattern)
docker stop my-postgres && docker rm my-postgres
```

### Debugging and Inspecting Containers

These are the commands that will save you hours when things go wrong:

```bash
# See real-time logs of a container
docker logs my-postgres

# Follow logs live (like tail -f)
docker logs -f my-postgres

# See only the last 50 lines
docker logs --tail 50 my-postgres

# Get a bash shell INSIDE a running container
docker exec -it my-postgres bash

# Or run a specific command inside the container
docker exec my-postgres env         # See all environment variables
docker exec my-postgres ls /var/lib # Inspect the filesystem

# Inspect ALL details about a container (returns JSON)
docker inspect my-postgres

# See resource usage in real time (CPU, memory, network)
docker stats

# See running processes inside a container
docker top my-postgres
```

### Cleanup Commands (Your System Will Thank You)

```bash
# Remove all stopped containers
docker container prune

# Remove all unused images
docker image prune

# Nuclear option ‚Äî remove EVERYTHING not currently in use
# (stopped containers, unused images, unused networks, build cache)
docker system prune -a

# See disk usage
docker system df
```

---

## Running Real Services: Practical Examples üöÄ

### 1. Spinning Up PostgreSQL

```bash
docker run -d \
  --name postgres-dev \
  -e POSTGRES_PASSWORD=password \
  -e POSTGRES_USER=myuser \
  -e POSTGRES_DB=mydb \
  -p 5432:5432 \
  postgres:15

# Connect to it using psql inside the container
docker exec -it postgres-dev psql -U myuser -d mydb
```

Now connect from your Node.js app using:
```
postgresql://myuser:password@localhost:5432/mydb
```

Your app talks to `localhost:5432` ‚Äî Docker handles the rest.

### 2. Running Redis

```bash
docker run -d \
  --name redis-dev \
  -p 6379:6379 \
  redis:alpine

# Test it
docker exec -it redis-dev redis-cli PING
# PONG  ‚úÖ
```

### 3. Running Ubuntu (For Exploring Linux)

```bash
# Drop into an interactive Ubuntu shell
docker run -it --rm ubuntu:22.04 bash

# --rm means: delete the container when you exit
# Perfect for temporary explorations
```

### 4. Running Your Own Node.js App

```bash
# 1. Build an image from your app's Dockerfile (more on this soon!)
docker build -t my-node-app .

# 2. Run it
docker run -d \
  --name my-app \
  -p 3000:3000 \
  -e DATABASE_URL=postgresql://... \
  my-node-app
```

---


## Wrapping Up üéÅ

We covered a LOT today. Let's recap the mental models that matter:

1. **Image = OS / Container = Machine running that OS** ‚Äî the analogy that makes it stick
2. **Containers are isolated** ‚Äî they can't see each other's data by default, just like separate laptops
3. **Docker vs VMs** ‚Äî containers share the host kernel, making them faster and lighter
4. **Images are layered** ‚Äî order your Dockerfile steps for maximum cache efficiency
5. **The CLI is your friend** ‚Äî `run`, `ps`, `logs`, `exec`, `rm` are your daily vocabulary

Docker is one of those tools where once you start using it, you can't imagine working without it. The "it works on my machine" problem doesn't just get solved ‚Äî it becomes a non-issue, forever.

**Next up**: We'll dive into **Docker Volumes** (persisting data across container restarts) and **Docker Compose** (running your entire application ‚Äî Node.js + Postgres + Redis ‚Äî with a single `docker-compose up` command). That's where Docker goes from cool to *essential*.

---

*Part of the Backend Journey series ‚Äî documenting the real-world path of a backend engineer, one concept at a time.*

**Find all the code and examples on [GitHub: Backend-Journey](https://github.com/ZoyaRasheed/Backend-Journey)**

Have questions? Drop a comment below! üëáüê≥
